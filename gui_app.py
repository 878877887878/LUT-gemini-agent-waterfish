import gradio as gr
import os
import sys
import warnings
from dotenv import load_dotenv
from PIL import Image

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# åŒ¯å…¥ v16.2 æ ¸å¿ƒçµ„ä»¶
from core.lut_engine import LUTEngine
from core.rag_core import KnowledgeBase
from core.smart_planner import SmartPlanner
from core.memory_manager import MemoryManager
from core.security import execute_safe_command
from core.logger import Logger
from core.gemini_client import GeminiClient  # [v16.2 New]

if sys.platform.startswith('win'):
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except Exception:
        pass

load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    print("âŒ éŒ¯èª¤: è«‹åœ¨ .env è¨­å®š GEMINI_API_KEY")
    sys.exit(1)

Logger.info("æ­£åœ¨å•Ÿå‹• GUI (v16.2 Unified Memory)...")

# åˆå§‹åŒ–
memory_mgr = MemoryManager()
lut_engine = LUTEngine()
rag = KnowledgeBase()

try:
    all_luts = lut_engine.list_luts()
    if all_luts:
        rag.index_luts(all_luts)
except Exception:
    pass

# [v16.2] å‚³å…¥ lut_engine èˆ‡åˆå§‹åŒ– GeminiClient
planner = SmartPlanner(API_KEY, rag, lut_engine)
client = GeminiClient(API_KEY)

# ç”¨æ–¼å„²å­˜å›é¥‹ç‹€æ…‹çš„ Global è®Šæ•¸
current_context = {}


# ================= å·¥å…·å‡½å¼ =================

def remember_user_preference(info: str):
    Logger.info(f"GUI è¨˜æ†¶: {info}")
    return memory_mgr.add_preference(info)


def check_available_luts(keyword: str = ""):
    all_names = list(lut_engine.lut_index.keys())
    if keyword:
        filtered = [n for n in all_names if keyword.lower() in n]
        if not filtered: return "ç„¡ç›¸é—œæ¿¾é¡ã€‚"
        return f"æ‰¾åˆ° {len(filtered)} å€‹..."

    # éš¨æ©Ÿå±•ç¤ºä¸€äº›ï¼Œé¿å…å¡çˆ†ç•«é¢
    import random
    sample_size = min(len(all_names), 30)
    sample = random.sample(all_names, sample_size) if all_names else []
    return f"å…± {len(all_names)} å€‹æ¿¾é¡ã€‚åŒ…å«: {', '.join(sample)}..."


def get_current_memory():
    mem = memory_mgr._load_memory()
    prefs = mem.get("user_preferences", [])
    if not prefs: return "ç„¡è³‡æ–™"
    return "\n".join([f"- {p}" for p in prefs])


# ================= å°è©±é‚è¼¯ (Unified Memory) =================

def get_or_create_session(session_state):
    """
    ç¢ºä¿ session å­˜åœ¨ã€‚ä½¿ç”¨ UnifiedChatSession ä»¥æ”¯æ´æ¨¡å‹è¼ªè©¢ã€‚
    """
    if session_state is None:
        tools = [execute_safe_command, remember_user_preference, check_available_luts]
        base_prompt = """
        ä½ æ˜¯ä¸€å€‹å¼·å¤§çš„ AI åŠ©ç† (Gemini 3 Pro)ã€‚
        ã€èƒ½åŠ›ã€‘ä¿®åœ–ã€æŸ¥è©¢æ¿¾é¡ã€è¨˜æ†¶åå¥½ã€‚
        è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
        """
        dynamic_context = memory_mgr.get_system_prompt_addition()

        # å»ºç«‹
        session_state = client.create_unified_chat(
            tools=tools,
            system_instruction=base_prompt + dynamic_context
        )
        Logger.info("GUI: å·²å»ºç«‹æ–°çš„ Unified Chat Session")

    return session_state


def chat_response(user_message, history, session_state):
    # å–å¾—æˆ–å»ºç«‹ Session
    session = get_or_create_session(session_state)

    try:
        Logger.debug(f"GUI å°è©±: {user_message}")
        # ç™¼é€è¨Šæ¯ (è‡ªå‹•è¼ªè©¢æ¨¡å‹)
        response = session.send_message(user_message)

        # Gradio çš„ history æ ¼å¼é€šå¸¸æ˜¯ List of [user, bot]
        # ä½†é€™è£¡æˆ‘å€‘ä½¿ç”¨ append æ–¹å¼æ›´æ–°
        history.append((user_message, response.text))
        return "", history, session

    except Exception as e:
        Logger.error(f"GUI å°è©±éŒ¯èª¤: {e}")
        history.append((user_message, f"âŒ éŒ¯èª¤: {str(e)}"))
        return "", history, session


# ================= è¦–è¦ºé‚è¼¯ =================

def process_image_smartly(image, user_req):
    Logger.info(f"GUI ä¿®åœ–éœ€æ±‚: {user_req}")
    if image is None: return None, "âŒ è«‹å…ˆä¸Šå‚³åœ–ç‰‡"
    if not user_req: user_req = "è‡ªå‹•èª¿æ•´"

    # å­˜æš«å­˜æª”çµ¦ AI çœ‹
    temp_path = "temp_gui_input.jpg"
    image.save(temp_path)

    # å‘¼å« Planner (å…§éƒ¨ä½¿ç”¨ GeminiClient è‡ªå‹•è¼ªè©¢)
    plan = planner.generate_plan(temp_path, user_req)

    if not plan or not plan.get('selected_lut'):
        return None, f"âš ï¸ AI æ€è€ƒå¤±æ•—: {plan.get('reasoning', 'æœªçŸ¥éŒ¯èª¤')}"

    # æ›´æ–° Context ä»¥ä¾›å›é¥‹ä½¿ç”¨
    global current_context
    current_context = {"req": user_req, "plan": plan}

    # åŸ·è¡Œèª¿è‰²
    final_img, msg = lut_engine.apply_lut(
        temp_path,
        plan['selected_lut'],
        intensity=plan.get('intensity', 1.0),
        brightness=plan.get('brightness', 1.0),
        saturation=plan.get('saturation', 1.0),
        temperature=plan.get('temperature', 0.0),
        tint=plan.get('tint', 0.0),
        contrast=plan.get('contrast', 1.0),
        curve_points=plan.get('curve_points'),
        sharpness=plan.get('sharpness', 1.0),
        simulate_log=plan.get('simulate_log', False),
        secondary_lut=plan.get('secondary_lut'),
        mix_ratio=plan.get('mix_ratio', 0.0)
    )

    # ç”¢ç”Ÿå ±å‘Š
    mix_info = ""
    if plan.get('secondary_lut'):
        mix_info = f"<br>â• æ··åˆ: `{plan.get('secondary_lut')}` ({plan.get('mix_ratio')})"

    curve_status = 'Custom' if plan.get('curve_points') else 'Linear'

    report = f"""### ğŸ§ª æ±ºç­–å ±å‘Š (v16.2)
**ç­–ç•¥**: {plan.get('style_strategy', 'ç„¡')}

| åƒæ•¸ | è¨­å®š |
| :--- | :--- |
| **LUT** | `{plan.get('selected_lut')}` {mix_info} |
| **å¼·åº¦** | {plan.get('intensity', 1.0)} |
| **WB** | T:{plan.get('temperature')} / Tint:{plan.get('tint')} |
| **Curve** | {curve_status} |

> {plan.get('caption', 'å®Œæˆ')}
"""
    return final_img, report


def send_feedback(is_positive):
    global current_context
    if not current_context: return "âš ï¸ ç„¡ç´€éŒ„"
    score = 1 if is_positive else -1
    planner.learn_from_result(current_context['req'], current_context['plan'], score)
    return "âœ… å·²è¨˜éŒ„" if is_positive else "â å·²è¨˜éŒ„"


# ================= GUI å»ºæ§‹ =================

with gr.Blocks(title="Gemini Agent v16.2", theme=gr.themes.Soft()) as app:
    gr.Markdown("# ğŸ¤– Gemini Agent v16.2 (Unified Memory)")

    # é€™è£¡å„²å­˜æˆ‘å€‘çš„ UnifiedChatSession ç‰©ä»¶ (è·¨è«‹æ±‚æŒä¹…åŒ–)
    chat_state = gr.State(None)

    with gr.Tabs():
        # Tab 1: ä¿®åœ–
        with gr.TabItem("ğŸ‘ï¸ æ™ºèƒ½ä¿®åœ–"):
            with gr.Row():
                with gr.Column(scale=1):
                    input_img = gr.Image(type="pil", label="è¼¸å…¥åœ–ç‰‡")
                    style_input = gr.Textbox(label="é¢¨æ ¼éœ€æ±‚", placeholder="ä¾‹å¦‚ï¼šæ—¥ç³»å†·ç™½ã€è† ç‰‡æ„Ÿã€é«˜å°æ¯”...")
                    btn_process = gr.Button("ğŸš€ é–‹å§‹ç…‰é‡‘", variant="primary")

                    gr.Markdown("### ğŸ“ çµæœå›é¥‹")
                    with gr.Row():
                        btn_good = gr.Button("ğŸ‘ æ»¿æ„ (å­¸ç¿’)")
                        btn_bad = gr.Button("ğŸ‘ ä¸æ»¿æ„ (é¿é›·)")
                    feedback_msg = gr.Label(show_label=False)

                with gr.Column(scale=1):
                    output_img = gr.Image(label="ä¿®åœ–çµæœ", type="pil")
                    output_info = gr.Markdown()

            btn_process.click(
                process_image_smartly,
                inputs=[input_img, style_input],
                outputs=[output_img, output_info]
            )
            btn_good.click(lambda: send_feedback(True), outputs=feedback_msg)
            btn_bad.click(lambda: send_feedback(False), outputs=feedback_msg)

        # Tab 2: å°è©±
        with gr.TabItem("ğŸ’¬ æ ¸å¿ƒå¤§è…¦"):
            chatbot = gr.Chatbot(height=500, label="Gemini 3 Pro")
            msg_input = gr.Textbox(label="è¼¸å…¥è¨Šæ¯", placeholder="èŠèŠå¤©ï¼Œæˆ–æŸ¥è©¢æ¿¾é¡...")

            msg_input.submit(
                chat_response,
                inputs=[msg_input, chatbot, chat_state],
                outputs=[msg_input, chatbot, chat_state]
            )

        # Tab 3: è¨˜æ†¶
        with gr.TabItem("ğŸ§  è¨˜æ†¶åº«"):
            memory_display = gr.Textbox(label="é•·æœŸè¨˜æ†¶", value=get_current_memory(), lines=10)
            gr.Button("ğŸ”„ åˆ·æ–°è¨˜æ†¶").click(get_current_memory, outputs=memory_display)

if __name__ == "__main__":
    app.queue().launch(inbrowser=True, server_name="127.0.0.1")